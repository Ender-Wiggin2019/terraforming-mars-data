{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFM Data Transform & Structuring\n",
    "\n",
    "Transform local data (`local_data/`) into readable, analysis-ready structures.\n",
    "\n",
    "**Prerequisites**\n",
    "1. Run `uv run preprocess` to fetch local data\n",
    "2. `local_data/tfm.db` exists with games, game_results, user_game_results tables\n",
    "\n",
    "**Output**: `local_data/tfm_analysis.db` - SQLite database with structured tables\n",
    "\n",
    "**Memory Optimization**: Uses chunked processing to handle large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source DB: ./local_data/tfm.db\n",
      "Analysis DB: ./local_data/tfm_analysis.db\n",
      "Chunk size: 500 games per batch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "LOCAL_DATA_DIR = './local_data'\n",
    "SOURCE_DB_PATH = os.path.join(LOCAL_DATA_DIR, 'tfm.db')\n",
    "ANALYSIS_DB_PATH = os.path.join(LOCAL_DATA_DIR, 'tfm_analysis.db')\n",
    "\n",
    "# Chunk size for processing large tables (adjust based on available memory)\n",
    "CHUNK_SIZE = 500  # Process 500 games at a time\n",
    "\n",
    "# Check source data exists\n",
    "if not os.path.exists(SOURCE_DB_PATH):\n",
    "    raise FileNotFoundError(f\"Source DB not found: {SOURCE_DB_PATH}\\nRun 'uv run preprocess' first\")\n",
    "\n",
    "print(f\"Source DB: {SOURCE_DB_PATH}\")\n",
    "print(f\"Analysis DB: {ANALYSIS_DB_PATH}\")\n",
    "print(f\"Chunk size: {CHUNK_SIZE} games per batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Source Data (Non-game Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games: 17201 rows (will process in chunks)\n",
      "game_results: 17817 rows\n",
      "user_game_results: 57102 rows\n",
      "user_rank: 6397 rows\n",
      "users: 7336 rows\n"
     ]
    }
   ],
   "source": [
    "# Load smaller tables into memory\n",
    "source_conn = sqlite3.connect(SOURCE_DB_PATH)\n",
    "\n",
    "# Get row counts first\n",
    "games_count = pd.read_sql('SELECT COUNT(*) as cnt FROM games', source_conn)['cnt'][0]\n",
    "game_results_df = pd.read_sql('SELECT * FROM game_results', source_conn)\n",
    "user_game_results_df = pd.read_sql('SELECT * FROM user_game_results', source_conn)\n",
    "\n",
    "# Load CSV\n",
    "user_rank_df = pd.read_csv(os.path.join(LOCAL_DATA_DIR, 'user_rank.csv'))\n",
    "users_df = pd.read_csv(os.path.join(LOCAL_DATA_DIR, 'users.csv'))\n",
    "\n",
    "source_conn.close()\n",
    "\n",
    "print(f\"games: {games_count} rows (will process in chunks)\")\n",
    "print(f\"game_results: {len(game_results_df)} rows\")\n",
    "print(f\"user_game_results: {len(user_game_results_df)} rows\")\n",
    "print(f\"user_rank: {len(user_rank_df)} rows\")\n",
    "print(f\"users: {len(users_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_safe(json_str):\n",
    "    \"\"\"Safely parse JSON string\"\"\"\n",
    "    if pd.isna(json_str):\n",
    "        return None\n",
    "    if isinstance(json_str, dict):\n",
    "        return json_str\n",
    "    if isinstance(json_str, str):\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                return eval(json_str)\n",
    "            except:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def split_corporation(corp_str):\n",
    "    \"\"\"Split corporation names (separated by |)\"\"\"\n",
    "    if pd.isna(corp_str) or corp_str == '':\n",
    "        return []\n",
    "    return [c.strip() for c in str(corp_str).split('|') if c.strip()]\n",
    "\n",
    "\n",
    "def clean_player_name(name):\n",
    "    \"\"\"Clean player name (remove prefix ~, @, ～ and lowercase)\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    name = str(name)\n",
    "    if name and name[0] in ['~', '@', '～']:\n",
    "        name = name[1:]\n",
    "    return name.lower()\n",
    "\n",
    "\n",
    "def is_bot_player(name):\n",
    "    \"\"\"Check if player is a bot\"\"\"\n",
    "    bot_names = {'green', '1', '2', '3', '4', 'red', 'blue', 'yellow',\n",
    "                 '绿色', '红色', '黄色', '蓝色'}\n",
    "    if pd.isna(name):\n",
    "        return True\n",
    "    return str(name).lower() in bot_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Flatten game_results Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_game_results(df):\n",
    "    \"\"\"\n",
    "    Flatten game_results.scores field\n",
    "    Expand each player's score into separate rows\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['scores_parsed'] = df['scores'].apply(parse_json_safe)\n",
    "\n",
    "    rows = []\n",
    "    for idx, row in df.iterrows():\n",
    "        scores = row['scores_parsed']\n",
    "        if not scores or not isinstance(scores, list):\n",
    "            continue\n",
    "\n",
    "        for position, score_data in enumerate(scores, start=1):\n",
    "            if not isinstance(score_data, dict):\n",
    "                continue\n",
    "\n",
    "            flat_row = {\n",
    "                'game_id': row['game_id'],\n",
    "                'seed_game_id': row.get('seed_game_id'),\n",
    "                'players': row['players'],\n",
    "                'generations': row['generations'],\n",
    "                'createtime': row['createtime'],\n",
    "                'position': position,\n",
    "                'player_name': clean_player_name(score_data.get('player')),\n",
    "                'player_name_raw': score_data.get('player'),\n",
    "                'player_score': score_data.get('playerScore'),\n",
    "                'corporation_raw': score_data.get('corporation'),\n",
    "            }\n",
    "\n",
    "            corps = split_corporation(score_data.get('corporation'))\n",
    "            flat_row['corporation_1'] = corps[0] if len(corps) > 0 else None\n",
    "            flat_row['corporation_2'] = corps[1] if len(corps) > 1 else None\n",
    "            flat_row['corporation_3'] = corps[2] if len(corps) > 2 else None\n",
    "            flat_row['corporation_count'] = len(corps)\n",
    "            flat_row['is_bot'] = is_bot_player(flat_row['player_name'])\n",
    "\n",
    "            rows.append(flat_row)\n",
    "\n",
    "    result_df = pd.DataFrame(rows)\n",
    "\n",
    "    if len(result_df) > 0:\n",
    "        result_df['rank'] = result_df.groupby('game_id')['player_score'] \\\n",
    "            .rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "flat_game_results_df = flatten_game_results(game_results_df)\n",
    "print(f\"Flattened game_results: {len(flat_game_results_df)} rows\")\n",
    "flat_game_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Process user_game_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_game_results(df):\n",
    "    \"\"\"\n",
    "    Process user_game_results table\n",
    "    - Split corporation names\n",
    "    - Clean player names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    corps_split = df['corporation'].apply(split_corporation)\n",
    "    df['corporation_1'] = corps_split.apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "    df['corporation_2'] = corps_split.apply(lambda x: x[1] if len(x) > 1 else None)\n",
    "    df['corporation_3'] = corps_split.apply(lambda x: x[2] if len(x) > 2 else None)\n",
    "    df['corporation_count'] = corps_split.apply(len)\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_ugr_df = process_user_game_results(user_game_results_df)\n",
    "print(f\"Processed user_game_results: {len(processed_ugr_df)} rows\")\n",
    "processed_ugr_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Chunked Game Data Processor\n",
    "\n",
    "Process games table in chunks to avoid memory issues.\n",
    "\n",
    "**Strategy**: Only process games that have corresponding game_results (LEFT JOIN logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_game_row(row):\n",
    "    \"\"\"\n",
    "    Process a single game row, extract all data\n",
    "    Returns: dict with cards, stats, milestones, awards, globals\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'cards': [],\n",
    "        'stats': [],\n",
    "        'milestones': [],\n",
    "        'awards': [],\n",
    "        'globals': []\n",
    "    }\n",
    "\n",
    "    game_data = parse_json_safe(row['game'])\n",
    "    if not game_data:\n",
    "        return result\n",
    "\n",
    "    game_id = row['game_id']\n",
    "    createtime = row['createtime']\n",
    "    generation = game_data.get('generation')\n",
    "    player_count = len(game_data.get('players', []))\n",
    "\n",
    "    # Extract player data\n",
    "    for player in game_data.get('players', []):\n",
    "        user_id = player.get('userId')\n",
    "        player_id = player.get('id')\n",
    "        player_name = player.get('name')\n",
    "        player_name_clean = clean_player_name(player_name)\n",
    "        tr = player.get('terraformRating')\n",
    "\n",
    "        corps = player.get('corporations', [])\n",
    "        corp_names = [c.get('name') for c in corps if c.get('name')]\n",
    "        corp_1 = corp_names[0] if len(corp_names) > 0 else None\n",
    "        corp_2 = corp_names[1] if len(corp_names) > 1 else None\n",
    "\n",
    "        # Extract played cards\n",
    "        for card_idx, card in enumerate(player.get('playedCards', [])):\n",
    "            result['cards'].append({\n",
    "                'game_id': game_id,\n",
    "                'createtime': createtime,\n",
    "                'user_id': user_id,\n",
    "                'player_id': player_id,\n",
    "                'player_name': player_name_clean,\n",
    "                'player_name_raw': player_name,\n",
    "                'terraform_rating': tr,\n",
    "                'corporation_1': corp_1,\n",
    "                'corporation_2': corp_2,\n",
    "                'card_order': card_idx + 1,\n",
    "                'card_name': card.get('name'),\n",
    "                'resource_count': card.get('resourceCount', 0),\n",
    "                'clone_tag': card.get('cloneTag'),\n",
    "                'bonus_resource': card.get('bonusResource'),\n",
    "                'is_disabled': card.get('isDisabled', False),\n",
    "            })\n",
    "\n",
    "        # Extract player stats\n",
    "        gps = player.get('globalParameterSteps', {})\n",
    "        timer = player.get('timer', {})\n",
    "        vp_by_gen = player.get('victoryPointsByGeneration', [])\n",
    "\n",
    "        result['stats'].append({\n",
    "            'game_id': game_id,\n",
    "            'createtime': createtime,\n",
    "            'generation': generation,\n",
    "            'user_id': user_id,\n",
    "            'player_id': player_id,\n",
    "            'player_name': player_name_clean,\n",
    "            'player_name_raw': player_name,\n",
    "            'corporation_1': corp_1,\n",
    "            'corporation_2': corp_2,\n",
    "            'terraform_rating': tr,\n",
    "            'victory_points_final': vp_by_gen[-1] if vp_by_gen else None,\n",
    "            'colony_victory_points': player.get('colonyVictoryPoints', 0),\n",
    "            'mega_credits': player.get('megaCredits'),\n",
    "            'mc_production': player.get('megaCreditProduction'),\n",
    "            'steel': player.get('steel'),\n",
    "            'steel_production': player.get('steelProduction'),\n",
    "            'titanium': player.get('titanium'),\n",
    "            'titanium_production': player.get('titaniumProduction'),\n",
    "            'plants': player.get('plants'),\n",
    "            'plant_production': player.get('plantProduction'),\n",
    "            'energy': player.get('energy'),\n",
    "            'energy_production': player.get('energyProduction'),\n",
    "            'heat': player.get('heat'),\n",
    "            'heat_production': player.get('heatProduction'),\n",
    "            'actions_taken': player.get('actionsTakenThisGame'),\n",
    "            'delegates_placed': player.get('totalDelegatesPlaced'),\n",
    "            'oceans_contributed': gps.get('oceans', 0),\n",
    "            'oxygen_contributed': gps.get('oxygen', 0),\n",
    "            'temperature_contributed': gps.get('temperature', 0),\n",
    "            'venus_contributed': gps.get('venus', 0),\n",
    "            'time_elapsed_ms': timer.get('sumElapsed'),\n",
    "            'fleet_size': player.get('fleetSize'),\n",
    "            'trades_this_generation': player.get('tradesThisGeneration'),\n",
    "            'cards_played_count': len(player.get('playedCards', [])),\n",
    "            'cards_in_hand_count': len(player.get('cardsInHand', [])),\n",
    "        })\n",
    "\n",
    "    # Extract milestones\n",
    "    for order, m in enumerate(game_data.get('claimedMilestones', []), start=1):\n",
    "        result['milestones'].append({\n",
    "            'game_id': game_id,\n",
    "            'createtime': createtime,\n",
    "            'milestone_name': m.get('milestone', {}).get('name'),\n",
    "            'player_id': m.get('player', {}).get('id'),\n",
    "            'claim_order': order,\n",
    "        })\n",
    "\n",
    "    # Extract awards\n",
    "    for order, a in enumerate(game_data.get('fundedAwards', []), start=1):\n",
    "        result['awards'].append({\n",
    "            'game_id': game_id,\n",
    "            'createtime': createtime,\n",
    "            'award_name': a.get('award', {}).get('name'),\n",
    "            'funder_player_id': a.get('player', {}).get('id'),\n",
    "            'fund_order': order,\n",
    "        })\n",
    "\n",
    "    # Extract global parameters per generation\n",
    "    for gen_idx, gen_data in enumerate(game_data.get('globalsPerGeneration', [])):\n",
    "        result['globals'].append({\n",
    "            'game_id': game_id,\n",
    "            'createtime': createtime,\n",
    "            'player_count': player_count,\n",
    "            'generation': gen_idx + 1,\n",
    "            'temperature': gen_data.get('temperature'),\n",
    "            'oxygen': gen_data.get('oxygen'),\n",
    "            'oceans': gen_data.get('oceans'),\n",
    "            'venus': gen_data.get('venus'),\n",
    "        })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_games_chunked(source_db_path, chunk_size=500):\n",
    "    \"\"\"\n",
    "    Process games table in chunks to avoid memory issues\n",
    "\n",
    "    Args:\n",
    "        source_db_path: Path to source SQLite database\n",
    "        chunk_size: Number of games to process per chunk\n",
    "\n",
    "    Returns:\n",
    "        dict with DataFrames: cards, stats, milestones, awards, globals\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(source_db_path)\n",
    "\n",
    "    # Only process games that have corresponding game_results (LEFT JOIN logic)\n",
    "    # This ensures we don't process games without results\n",
    "    total_count = pd.read_sql(\n",
    "        \"\"\"SELECT COUNT(*) as cnt FROM games g\n",
    "           INNER JOIN (SELECT DISTINCT game_id FROM game_results) gr\n",
    "           ON g.game_id = gr.game_id\n",
    "           WHERE g.status IN ('finished', 'end')\"\"\", conn\n",
    "    )['cnt'][0]\n",
    "\n",
    "    games_without_results = pd.read_sql(\n",
    "        \"\"\"SELECT COUNT(*) as cnt FROM games g\n",
    "           WHERE g.status IN ('finished', 'end')\n",
    "           AND g.game_id NOT IN (SELECT DISTINCT game_id FROM game_results)\"\"\", conn\n",
    "    )['cnt'][0]\n",
    "\n",
    "    print(f\"Games with game_results to process: {total_count}\")\n",
    "    print(f\"Games without game_results (skipped): {games_without_results}\")\n",
    "    print(f\"Chunk size: {chunk_size}\")\n",
    "    print(f\"Estimated chunks: {(total_count + chunk_size - 1) // chunk_size}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Initialize result containers\n",
    "    all_cards = []\n",
    "    all_stats = []\n",
    "    all_milestones = []\n",
    "    all_awards = []\n",
    "    all_globals = []\n",
    "\n",
    "    offset = 0\n",
    "    chunk_num = 0\n",
    "\n",
    "    while offset < total_count:\n",
    "        chunk_num += 1\n",
    "\n",
    "        # Fetch chunk - only games with game_results\n",
    "        sql = f\"\"\"\n",
    "            SELECT g.game_id, g.game, g.status, g.createtime\n",
    "            FROM games g\n",
    "            INNER JOIN (SELECT DISTINCT game_id FROM game_results) gr\n",
    "            ON g.game_id = gr.game_id\n",
    "            WHERE g.status IN ('finished', 'end')\n",
    "            LIMIT {chunk_size} OFFSET {offset}\n",
    "        \"\"\"\n",
    "        chunk_df = pd.read_sql(sql, conn)\n",
    "\n",
    "        if len(chunk_df) == 0:\n",
    "            break\n",
    "\n",
    "        print(f\"Chunk {chunk_num}: Processing {len(chunk_df)} games (offset {offset})...\")\n",
    "\n",
    "        # Process each game in chunk\n",
    "        for _, row in chunk_df.iterrows():\n",
    "            result = process_game_row(row)\n",
    "            all_cards.extend(result['cards'])\n",
    "            all_stats.extend(result['stats'])\n",
    "            all_milestones.extend(result['milestones'])\n",
    "            all_awards.extend(result['awards'])\n",
    "            all_globals.extend(result['globals'])\n",
    "\n",
    "        # Clear chunk from memory\n",
    "        del chunk_df\n",
    "        gc.collect()\n",
    "\n",
    "        # Progress report\n",
    "        processed = min(offset + chunk_size, total_count)\n",
    "        print(f\"  -> Progress: {processed}/{total_count} ({processed*100//total_count}%)\")\n",
    "        print(f\"  -> Cards: {len(all_cards)}, Stats: {len(all_stats)}, Milestones: {len(all_milestones)}\")\n",
    "\n",
    "        offset += chunk_size\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "    return {\n",
    "        'cards': pd.DataFrame(all_cards) if all_cards else pd.DataFrame(),\n",
    "        'stats': pd.DataFrame(all_stats) if all_stats else pd.DataFrame(),\n",
    "        'milestones': pd.DataFrame(all_milestones) if all_milestones else pd.DataFrame(),\n",
    "        'awards': pd.DataFrame(all_awards) if all_awards else pd.DataFrame(),\n",
    "        'globals': pd.DataFrame(all_globals) if all_globals else pd.DataFrame(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Execute Chunked Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process games in chunks\n",
    "print(\"Starting chunked game processing...\")\n",
    "print(f\"Memory-efficient mode: {CHUNK_SIZE} games per batch\\n\")\n",
    "\n",
    "game_data = process_games_chunked(SOURCE_DB_PATH, chunk_size=CHUNK_SIZE)\n",
    "\n",
    "# Assign to individual DataFrames\n",
    "played_cards_df = game_data['cards']\n",
    "player_stats_df = game_data['stats']\n",
    "milestones_df = game_data['milestones']\n",
    "awards_df = game_data['awards']\n",
    "globals_df = game_data['globals']\n",
    "\n",
    "# Clean up\n",
    "del game_data\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nExtracted data summary:\")\n",
    "print(f\"  played_cards: {len(played_cards_df)} rows\")\n",
    "print(f\"  player_stats: {len(player_stats_df)} rows\")\n",
    "print(f\"  milestones: {len(milestones_df)} rows\")\n",
    "print(f\"  awards: {len(awards_df)} rows\")\n",
    "print(f\"  global_parameters: {len(globals_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Save to Analysis Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_analysis_db(dataframes_dict, db_path):\n",
    "    \"\"\"\n",
    "    Save multiple DataFrames to SQLite analysis database\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    try:\n",
    "        for table_name, df in dataframes_dict.items():\n",
    "            if df is not None and len(df) > 0:\n",
    "                df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "                print(f\"✓ Saved {table_name}: {len(df)} rows\")\n",
    "            else:\n",
    "                print(f\"⚠ Skipped {table_name}: no data\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    print(f\"\\nDatabase saved: {db_path}\")\n",
    "\n",
    "tables_to_save = {\n",
    "    'flat_game_results': flat_game_results_df,\n",
    "    'processed_user_game_results': processed_ugr_df,\n",
    "    'user_rank': user_rank_df,\n",
    "    'users': users_df,\n",
    "    'played_cards': played_cards_df,\n",
    "    'player_stats': player_stats_df,\n",
    "    'milestones': milestones_df,\n",
    "    'awards': awards_df,\n",
    "    'global_parameters': globals_df,\n",
    "}\n",
    "\n",
    "save_to_analysis_db(tables_to_save, ANALYSIS_DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(ANALYSIS_DB_PATH)\n",
    "\n",
    "tables = pd.read_sql(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table'\", conn\n",
    ")['name'].tolist()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Analysis Database Schema\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for table in tables:\n",
    "    count = pd.read_sql(f'SELECT COUNT(*) as cnt FROM {table}', conn)['cnt'][0]\n",
    "    cols = pd.read_sql(f'PRAGMA table_info({table})', conn)['name'].tolist()\n",
    "    print(f\"\\n[{table}] {count} rows\")\n",
    "    print(f\"  Columns: {', '.join(cols[:8])}{'...' if len(cols) > 8 else ''}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(ANALYSIS_DB_PATH)\n",
    "\n",
    "# Example 1: Corporation win rate (excluding bots)\n",
    "sql_corp_win_rate = \"\"\"\n",
    "SELECT\n",
    "    corporation_1 as corporation,\n",
    "    players,\n",
    "    COUNT(*) as total_games,\n",
    "    SUM(CASE WHEN rank = 1 THEN 1 ELSE 0 END) as wins,\n",
    "    ROUND(SUM(CASE WHEN rank = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as win_rate,\n",
    "    ROUND(AVG(player_score), 1) as avg_score\n",
    "FROM flat_game_results\n",
    "WHERE is_bot = 0\n",
    "  AND corporation_1 IS NOT NULL\n",
    "GROUP BY corporation_1, players\n",
    "HAVING total_games >= 10\n",
    "ORDER BY players, win_rate DESC\n",
    "\"\"\"\n",
    "print(\"Corporation Win Rate (excl. bots, min 10 games):\")\n",
    "pd.read_sql(sql_corp_win_rate, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Card win rate (joined with user_game_results)\n",
    "sql_card_win_rate = \"\"\"\n",
    "SELECT\n",
    "    pc.card_name,\n",
    "    COUNT(*) as play_count,\n",
    "    SUM(CASE WHEN ugr.position = 1 THEN 1 ELSE 0 END) as wins,\n",
    "    ROUND(SUM(CASE WHEN ugr.position = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as win_rate,\n",
    "    ROUND(AVG(ugr.player_score), 1) as avg_score\n",
    "FROM played_cards pc\n",
    "JOIN processed_user_game_results ugr\n",
    "    ON pc.game_id = ugr.game_id AND pc.user_id = ugr.user_id\n",
    "WHERE ugr.phase = 'end'\n",
    "GROUP BY pc.card_name\n",
    "HAVING play_count >= 20\n",
    "ORDER BY win_rate DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "print(\"Card Win Rate TOP 20 (min 20 plays):\")\n",
    "pd.read_sql(sql_card_win_rate, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"\\nData transform complete!\")\n",
    "print(f\"Analysis DB: {ANALYSIS_DB_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
